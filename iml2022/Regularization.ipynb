{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/9z6xww6d6fq08blg2b3v_6_r0000gn/T/ipykernel_84494/2648700738.py:10: DeprecationWarning:\n",
      "\n",
      "Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Source: Alexandru Tifrea and Fanny Yang, 2021.\n",
    "# Based on an earlier version by Sebastian Curi and Andreas Krause.\n",
    "\n",
    "# Python Notebook Commands\n",
    "%reload_ext autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# General math and plotting modules.\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Widget and formatting modules\n",
    "import ipywidgets\n",
    "from ipywidgets import interact, interactive, interact_manual, fixed, widgets\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = (10, 6)\n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "# Machine Learning library.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "\n",
    "rcParams['figure.figsize'] = (15, 6)\n",
    "rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression with polynomial features\n",
    "\n",
    "In the following we show how the estimator depends on hyperparameters like the regularization coefficient (for LASSO and ridge penalties) or the the degree of the polynomial used for the features.\n",
    "\n",
    "\n",
    "Let's consider 1-dimensional data $\\{(x_i, y_i)\\}_{i=0}^n \\subset \\mathbb{R} \\times \\mathbb{R}$. We use a polynomial kernel of the form $k(x, z)=1 + xz + (xz)^2+...+(xz)^d$ for the regression task. This kernel induces a feature representation of the data in the space of monomials of degree at most $d$, i.e. $\\varphi: \\mathbb{R} \\rightarrow span(\\{1, X, X^2, ..., X^d\\})$. Minimizing the kernel regression objective is equivalent to performing linear regression in this feature space. The maximum degree controls the complexity of the kernel function.\n",
    "\n",
    "The kernel ridge regression that is minimized below can be written as: $L(w; \\lambda) := \\sum_{i=0}^n (y_i - w^T\\varphi(x_i))^2 + \\lambda ||w||_2^2 $.\n",
    "\n",
    "Below we show the mean squared error (MSE) computed on the training points, as well as the L2 error of the estimator compared to the ground truth function $f^*$, i.e. $||\\hat{f}-f^*||_{L_2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7424a67692e74c3e9373e08325818314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, continuous_update=False, description='Number of samples:', min=5, st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def true_regression_fun(X):\n",
    "    return np.cos(3 * np.pi * X)\n",
    "\n",
    "\n",
    "def poly_kernel_regression(n_samples, degree, reg_type, reg_coef, noise):\n",
    "    np.random.seed(101)\n",
    "\n",
    "    X = np.sort(np.random.rand(n_samples))\n",
    "    y = true_regression_fun(X) + np.random.randn(n_samples) * noise\n",
    "\n",
    "    if reg_type == \"ridge\" and reg_coef > 0:\n",
    "      model = Ridge(alpha=reg_coef, fit_intercept=False, solver=\"svd\")\n",
    "      model_key = \"ridge\"\n",
    "    elif reg_type == \"lasso\" and reg_coef > 0:\n",
    "      model = Lasso(alpha=reg_coef, fit_intercept=False, tol=1e-2, max_iter=10000)\n",
    "      model_key = \"lasso\"\n",
    "    else:\n",
    "      model = LinearRegression(fit_intercept=False)\n",
    "      model_key = \"linearregression\"\n",
    "    \n",
    "    clf = make_pipeline(PolynomialFeatures(degree), model)\n",
    "    clf.fit(X[:, np.newaxis], y)\n",
    "\n",
    "    X_test = np.sort(np.concatenate((np.linspace(0 - 1e-4, 1 + 1e-4, 100), X)))\n",
    "    train_mse = mean_squared_error(\n",
    "      y_true=y,\n",
    "      y_pred=clf.predict(X[:, np.newaxis])\n",
    "    )\n",
    "    test_mse = mean_squared_error(\n",
    "      y_true=true_regression_fun(X_test),\n",
    "      y_pred=clf.predict(X_test[:, np.newaxis])\n",
    "    )\n",
    "    \n",
    "    fig = make_subplots(rows=2, cols=1, row_width=[0.15, 0.35])\n",
    "    fig.add_trace(go.Scatter(x=X_test,\n",
    "                             y=clf.predict(X_test[:, np.newaxis]),\n",
    "                             line_width=3,\n",
    "                             name=\"Model\"),\n",
    "                  row=1,\n",
    "                  col=1)\n",
    "    fig.add_trace(go.Scatter(x=X_test,\n",
    "                             y=true_regression_fun(X_test),\n",
    "                             line_dash=\"dash\",\n",
    "                             line_width=3,\n",
    "                             name=\"True function\"),\n",
    "                  row=1,\n",
    "                  col=1)\n",
    "    fig.add_trace(go.Scatter(x=X,\n",
    "                             y=y,\n",
    "                             mode=\"markers\",\n",
    "                             marker_size=7,\n",
    "                             marker_symbol=\"x\",\n",
    "                             marker_color=\"black\",\n",
    "                             name=\"Samples\"),\n",
    "                  row=1,\n",
    "                  col=1)\n",
    "    fig.add_trace(go.Scatter(x=np.arange(clf[model_key].coef_.shape[0]),\n",
    "                             y=np.fabs(clf[model_key].coef_),\n",
    "                             line_width=3,\n",
    "                             showlegend=False),\n",
    "                  row=2,\n",
    "                  col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Training MSE = {train_mse:.6}\" + \"<br>L2 error\" + f\" = {test_mse:.6}\",\n",
    "        margin=go.layout.Margin(\n",
    "            l=0,  #left margin\n",
    "            r=0,  #right margin\n",
    "            b=0,  #bottom margin\n",
    "            t=60,  #top margin\n",
    "        ),\n",
    "        xaxis1_range=[0, 1],\n",
    "        xaxis1_title=\"x\",\n",
    "        yaxis1_range=[-2, 2],\n",
    "        yaxis1_title=\"y\",\n",
    "        xaxis2_title=\"Degree\",\n",
    "        yaxis2_title=\"Abs. value of coefficient\",\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "_ = interact(\n",
    "    poly_kernel_regression,\n",
    "    n_samples=ipywidgets.IntSlider(value=20,\n",
    "                                   min=5,\n",
    "                                   max=100,\n",
    "                                   step=5,\n",
    "                                   description='Number of samples:',\n",
    "                                   style={'description_width': 'initial'},\n",
    "                                   continuous_update=False),\n",
    "    degree=ipywidgets.IntSlider(value=10,\n",
    "                                min=1,\n",
    "                                max=30,\n",
    "                                step=1,\n",
    "                                description='Polynomial Degree:',\n",
    "                                style={'description_width': 'initial'},\n",
    "                                continuous_update=False),\n",
    "    reg_type=ipywidgets.Dropdown(options=[\"lasso\", \"ridge\"],\n",
    "                                 value=\"ridge\",\n",
    "                                 description='Regularization type:',\n",
    "                                 disabled=False,\n",
    "                                 style={'description_width': 'initial'},\n",
    "                                 continuous_update=False),\n",
    "    reg_coef=ipywidgets.FloatSlider(value=0.,\n",
    "                                    min=0,\n",
    "                                    max=0.001,\n",
    "                                    step=0.0001,\n",
    "                                    readout_format='.4f',\n",
    "                                    description='Regularization coefficient:',\n",
    "                                    style={'description_width': 'initial'},\n",
    "                                    continuous_update=False),\n",
    "    noise=ipywidgets.FloatSlider(value=0.5,\n",
    "                                 min=0,\n",
    "                                 max=1,\n",
    "                                 step=0.1,\n",
    "                                 readout_format='.2f',\n",
    "                                 description='Noise level:',\n",
    "                                 style={'description_width': 'initial'},\n",
    "                                 continuous_update=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of noise on the estimator norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9dff50169f14334be565af3fe27ac4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, continuous_update=False, description='Number of samples:', min=10, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def norm_increase_with_noise(n_samples, degree):\n",
    "    np.random.seed(101)\n",
    "    \n",
    "    noise_values = np.arange(0, 1.1, 0.1)\n",
    "    l1_norms, l2_norms = [], []\n",
    "    \n",
    "    X = np.sort(np.random.rand(n_samples))\n",
    "    gauss_noise = np.random.randn(n_samples)\n",
    "    for noise in noise_values:\n",
    "      y = true_regression_fun(X) + gauss_noise * noise\n",
    "\n",
    "      clf = make_pipeline(\n",
    "          PolynomialFeatures(degree),\n",
    "          LinearRegression(fit_intercept=False))\n",
    "      clf.fit(X[:, np.newaxis], y)\n",
    "      l1_norms.append(np.linalg.norm(clf[\"linearregression\"].coef_, ord=1))\n",
    "      l2_norms.append(np.linalg.norm(clf[\"linearregression\"].coef_, ord=2))\n",
    "    \n",
    "    l1_norms = np.array(l1_norms) / np.sqrt(degree)\n",
    "    l2_norms = np.array(l2_norms) / np.sqrt(degree)\n",
    "    \n",
    "    fig = make_subplots(rows=1, cols=2)\n",
    "    fig.add_trace(go.Scatter(x=noise_values,\n",
    "                             y=l1_norms,\n",
    "                             line_width=3,\n",
    "                             name=\"l1 norm\",\n",
    "                             showlegend=False),\n",
    "                  row=1,\n",
    "                  col=1)\n",
    "    fig.add_trace(go.Scatter(x=noise_values,\n",
    "                             y=l2_norms,\n",
    "                             line_width=3,\n",
    "                             name=\"l2 norm\",\n",
    "                             showlegend=False),\n",
    "                  row=1,\n",
    "                  col=2)\n",
    "\n",
    "    fig.update_layout(\n",
    "        margin=go.layout.Margin(\n",
    "            l=0,  #left margin\n",
    "            r=0,  #right margin\n",
    "            b=0,  #bottom margin\n",
    "            t=10,  #top margin\n",
    "        ),\n",
    "        xaxis1_title=\"Noise level\",\n",
    "        yaxis1_title=\"$\\ell_1\\ norm$\",\n",
    "        xaxis2_title=\"Noise level\",\n",
    "        yaxis2_title=\"$\\ell_2\\ norm$\",\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "_ = interact(\n",
    "    norm_increase_with_noise,\n",
    "    n_samples=ipywidgets.IntSlider(value=20,\n",
    "                                   min=10,\n",
    "                                   max=100,\n",
    "                                   step=5,\n",
    "                                   description='Number of samples:',\n",
    "                                   style={'description_width': 'initial'},\n",
    "                                   continuous_update=False),\n",
    "    degree=ipywidgets.IntSlider(value=10,\n",
    "                                min=10,\n",
    "                                max=30,\n",
    "                                step=1,\n",
    "                                description='Polynomial Degree:',\n",
    "                                style={'description_width': 'initial'},\n",
    "                                continuous_update=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

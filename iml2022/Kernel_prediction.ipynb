{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Source: Alexandru Tifrea and Fanny Yang, 2022.\n",
    "# Based on an earlier version by Sebastian Curi and Andreas Krause.\n",
    "\n",
    "# Python Notebook Commands\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# General math and plotting modules.\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Widget and formatting modules\n",
    "import ipywidgets\n",
    "from ipywidgets import interact, interactive, interact_manual, fixed, widgets\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = (15, 6)\n",
    "rcParams['font.size'] = 20\n",
    "\n",
    "# Machine Learning library.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "\n",
    "MAX_NUM_SAMPLES = 100\n",
    "figure_width = 1500\n",
    "figure_height = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression with polynomial kernels\n",
    "\n",
    "In the following we show how the estimator depends on hyperparameters like the ridge coefficient or the the degree of the polynomial used for to define the kernel.\n",
    "\n",
    "\n",
    "Let's consider 1-dimensional data $\\{(x_i, y_i)\\}_{i=0}^n \\subset \\mathbb{R} \\times \\mathbb{R}$. We use a polynomial kernel of the form $k(x, z)=1 + xz + (xz)^2+...+(xz)^d$ for the regression task. This kernel induces a feature representation of the data in the space of monomials of degree at most $d$, i.e. $\\varphi: \\mathbb{R} \\rightarrow span(\\{1, X, X^2, ..., X^d\\})$. Minimizing the kernel regression objective is equivalent to performing linear regression in this feature space. The maximum degree controls the complexity of the kernel function.\n",
    "\n",
    "The kernel ridge regression that is minimized below can be written as: $L(w; \\lambda) := \\sum_{i=0}^n (y_i - w^T\\varphi(x_i))^2 + \\lambda ||w||_2^2 $.\n",
    "\n",
    "Below we show the mean squared error (MSE) computed on the training points, as well as the L2 error of the estimator compared to the ground truth function $f^*$, i.e. $||\\hat{f}-f^*||_{L_2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709cd924159e42cfa81752f0d9c3282e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, continuous_update=False, description='Number of samples:', min=5, stâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def true_regression_fun(X):\n",
    "    return np.cos(3 * np.pi * X)\n",
    "\n",
    "\n",
    "def poly_kernel_regression(n_samples, degree, l2_coef, noise):\n",
    "    np.random.seed(101)\n",
    "    X = np.sort(np.random.rand(MAX_NUM_SAMPLES))\n",
    "    gaussian_noise = np.random.randn(MAX_NUM_SAMPLES)\n",
    "    idx = np.random.choice(np.arange(MAX_NUM_SAMPLES), n_samples)\n",
    "    X, gaussian_noise = X[idx], gaussian_noise[idx]\n",
    "    y = true_regression_fun(X) + gaussian_noise * noise\n",
    "\n",
    "    clf = make_pipeline(\n",
    "        PolynomialFeatures(degree),\n",
    "        Ridge(alpha=l2_coef, fit_intercept=False, solver=\"svd\"))\n",
    "    clf.fit(X[:, np.newaxis], y)\n",
    "\n",
    "    X_test = np.sort(np.concatenate((np.linspace(0 - 1e-4, 1 + 1e-4, 100), X)))\n",
    "    train_mse = mean_squared_error(\n",
    "      y_true=y,\n",
    "      y_pred=clf.predict(X[:, np.newaxis])\n",
    "    )\n",
    "    test_mse = mean_squared_error(\n",
    "      y_true=true_regression_fun(X_test),\n",
    "      y_pred=clf.predict(X_test[:, np.newaxis])\n",
    "    )\n",
    "    \n",
    "    fig = make_subplots(rows=2, cols=1, row_width=[0.15, 0.35])\n",
    "    fig.add_trace(go.Scatter(x=X_test,\n",
    "                             y=clf.predict(X_test[:, np.newaxis]),\n",
    "                             line_width=3,\n",
    "                             name=\"Model\"),\n",
    "                  row=1,\n",
    "                  col=1)\n",
    "    fig.add_trace(go.Scatter(x=X_test,\n",
    "                             y=true_regression_fun(X_test),\n",
    "                             line_dash=\"dash\",\n",
    "                             line_width=3,\n",
    "                             name=\"True function\"),\n",
    "                  row=1,\n",
    "                  col=1)\n",
    "    fig.add_trace(go.Scatter(x=X,\n",
    "                             y=y,\n",
    "                             mode=\"markers\",\n",
    "                             marker_size=7,\n",
    "                             marker_symbol=\"x\",\n",
    "                             marker_color=\"black\",\n",
    "                             name=\"Samples\"),\n",
    "                  row=1,\n",
    "                  col=1)\n",
    "    fig.add_trace(go.Scatter(x=np.arange(clf[\"ridge\"].coef_.shape[0]),\n",
    "                             y=np.fabs(clf[\"ridge\"].coef_),\n",
    "                             line_width=3,\n",
    "                             showlegend=False),\n",
    "                  row=2,\n",
    "                  col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=figure_width, \n",
    "        height=figure_height,\n",
    "        title=f\"Training MSE = {train_mse:.6}\" + \"<br>L2 error\" + f\" = {test_mse:.6}\",\n",
    "        margin=go.layout.Margin(\n",
    "            l=0,  #left margin\n",
    "            r=0,  #right margin\n",
    "            b=0,  #bottom margin\n",
    "            t=60,  #top margin\n",
    "        ),\n",
    "        xaxis1_range=[0, 1],\n",
    "        xaxis1_title=\"x\",\n",
    "        yaxis1_range=[-2, 2],\n",
    "        yaxis1_title=\"y\",\n",
    "        xaxis2_title=\"Degree\",\n",
    "        yaxis2_title=\"Abs. value of coefficient\",\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "_ = interact(\n",
    "    poly_kernel_regression,\n",
    "    n_samples=ipywidgets.IntSlider(value=20,\n",
    "                                   min=5,\n",
    "                                   max=MAX_NUM_SAMPLES,\n",
    "                                   step=5,\n",
    "                                   description='Number of samples:',\n",
    "                                   style={'description_width': 'initial'},\n",
    "                                   continuous_update=False),\n",
    "    degree=ipywidgets.IntSlider(value=10,\n",
    "                                min=1,\n",
    "                                max=30,\n",
    "                                step=1,\n",
    "                                description='Polynomial Degree:',\n",
    "                                style={'description_width': 'initial'},\n",
    "                                continuous_update=False),\n",
    "    l2_coef=ipywidgets.FloatSlider(value=0.,\n",
    "                                   min=0,\n",
    "                                   max=0.001,\n",
    "                                   step=0.0001,\n",
    "                                   readout_format='.4f',\n",
    "                                   description='Ridge coefficient:',\n",
    "                                   style={'description_width': 'initial'},\n",
    "                                   continuous_update=False),\n",
    "    noise=ipywidgets.FloatSlider(value=0.5,\n",
    "                                 min=0,\n",
    "                                 max=1,\n",
    "                                 step=0.1,\n",
    "                                 readout_format='.2f',\n",
    "                                 description='Noise level:',\n",
    "                                 style={'description_width': 'initial'},\n",
    "                                 continuous_update=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression with RBF kernels\n",
    "\n",
    "In the following we show how the estimator depends on hyperparameters like the ridge coefficient or the bandwidth for two commonly used radial basis function (RBF) kernels: the Gaussian and the Laplacian kernels. RBF kernels differ from polynomial kernels in that they induce a feature map from the inputs to an infinite-dimensional space.\n",
    "\n",
    "The general form of RBF kernels is $k(x, z) = \\exp\\left( \\frac{|x-z|^p}{\\sigma}\\right)$; for $p=1$ and $p=2$ we recover the Laplacian and the Gaussian kernel, respectively. The bandwidth $\\sigma$ controls the smoothness of prediction function.\n",
    "\n",
    "Below we show the mean squared error (MSE) computed on the training points, as well as the L2 error of the estimator compared to the ground truth function $f^*$, i.e. $||\\hat{f}-f^*||_{L_2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def rbf_kernel_regression(kernel_str, n_samples, bandwidth, l2_coef, noise):\n",
    "    np.random.seed(101) \n",
    "    X = np.sort(np.random.rand(MAX_NUM_SAMPLES))\n",
    "    gaussian_noise = np.random.randn(MAX_NUM_SAMPLES)\n",
    "    idx = np.random.choice(np.arange(MAX_NUM_SAMPLES), n_samples)\n",
    "    X, gaussian_noise = X[idx], gaussian_noise[idx]\n",
    "    y = true_regression_fun(X) + gaussian_noise * noise\n",
    "\n",
    "    gamma = np.power(10., -bandwidth)\n",
    "    if kernel_str == 'Gaussian':\n",
    "        kernel = \"rbf\"\n",
    "    elif kernel_str == 'Laplacian':\n",
    "        kernel = \"laplacian\"\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        orig_X = deepcopy(X)\n",
    "        X = X[:, np.newaxis]\n",
    "        clf = KernelRidge(alpha=l2_coef, kernel=kernel, gamma=gamma)   \n",
    "        clf.fit(X, y)\n",
    "    \n",
    "    X_test = np.sort(np.concatenate((np.linspace(0 - 1e-4, 1 + 1e-4, 100), orig_X)))\n",
    "    orig_X_test = deepcopy(X_test)\n",
    "    X_test = X_test[:, np.newaxis]\n",
    "\n",
    "    train_mse = mean_squared_error(\n",
    "      y_true=y,\n",
    "      y_pred=clf.predict(X)\n",
    "    )\n",
    "    test_mse = mean_squared_error(\n",
    "      y_true=true_regression_fun(orig_X_test),\n",
    "      y_pred=clf.predict(X_test)\n",
    "    )\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=orig_X_test,\n",
    "                   y=clf.predict(X_test),\n",
    "                   line_width=3,\n",
    "                   name=\"Model\"))\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=orig_X_test,\n",
    "                   y=true_regression_fun(orig_X_test),\n",
    "                   line_dash=\"dash\",\n",
    "                   line_width=3,\n",
    "                   name=\"True function\"))\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=orig_X,\n",
    "                   y=y,\n",
    "                   mode=\"markers\",\n",
    "                   marker_size=7,\n",
    "                   marker_symbol=\"x\",\n",
    "                   marker_color=\"black\",\n",
    "                   name=\"Samples\"))\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=figure_width, \n",
    "        height=figure_height,\n",
    "        title=f\"{kernel_str} kernel\" + \"<br>\" + f\"Training MSE = {train_mse:.6}\" + \"<br>L2 error\" + f\" = {test_mse:.6}\",\n",
    "        margin=go.layout.Margin(\n",
    "            l=0,  #left margin\n",
    "            r=0,  #right margin\n",
    "            b=0,  #bottom margin\n",
    "            t=95,  #top margin\n",
    "        ),\n",
    "        xaxis_range=[0, 1],\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_range=[-2, 2],\n",
    "        yaxis_title=\"y\",\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd412989f484a7cbc69bc4a588dcbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=30, continuous_update=False, description='Number of samples:', min=10, sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = interact(\n",
    "    rbf_kernel_regression,\n",
    "    kernel_str=ipywidgets.fixed(\"Gaussian\"),\n",
    "    bandwidth=ipywidgets.FloatSlider(value=-3,\n",
    "                                     min=-4,\n",
    "                                     max=-2,\n",
    "                                     step=0.1,\n",
    "                                     readout_format='.1f',\n",
    "                                     description='Bandwidth 10^:',\n",
    "                                     style={'description_width': 'initial'},\n",
    "                                     continuous_update=False),\n",
    "    n_samples=ipywidgets.IntSlider(value=30,\n",
    "                                   min=10,\n",
    "                                   max=MAX_NUM_SAMPLES,\n",
    "                                   step=10,\n",
    "                                   description='Number of samples:',\n",
    "                                   style={'description_width': 'initial'},\n",
    "                                   continuous_update=False),\n",
    "    l2_coef=ipywidgets.FloatSlider(value=0.,\n",
    "                                 min=0,\n",
    "                                 max=1.,\n",
    "                                 step=0.0001,\n",
    "                                 readout_format='.5f',\n",
    "                                 description='Ridge coefficient:',\n",
    "                                 style={'description_width': 'initial'},\n",
    "                                 continuous_update=False),\n",
    "    noise=ipywidgets.FloatSlider(value=0.1,\n",
    "                                 min=0,\n",
    "                                 max=0.5,\n",
    "                                 step=0.01,\n",
    "                                 readout_format='.2f',\n",
    "                                 description='Noise level:',\n",
    "                                 style={'description_width': 'initial'},\n",
    "                                 continuous_update=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c58b6a1de745be9ccbe0b2e8cb7396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=30, continuous_update=False, description='Number of samples:', min=10, sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = interact(\n",
    "    rbf_kernel_regression,\n",
    "    kernel_str=ipywidgets.fixed(\"Laplacian\"),\n",
    "    bandwidth=ipywidgets.FloatSlider(value=-1,\n",
    "                                     min=-2,\n",
    "                                     max=0,\n",
    "                                     step=0.1,\n",
    "                                     readout_format='.1f',\n",
    "                                     description='Bandwidth 10^:',\n",
    "                                     style={'description_width': 'initial'},\n",
    "                                     continuous_update=False),\n",
    "    n_samples=ipywidgets.IntSlider(value=30,\n",
    "                                   min=10,\n",
    "                                   max=MAX_NUM_SAMPLES,\n",
    "                                   step=10,\n",
    "                                   description='Number of samples:',\n",
    "                                   style={'description_width': 'initial'},\n",
    "                                   continuous_update=False),\n",
    "    l2_coef=ipywidgets.FloatSlider(value=0.,\n",
    "                                 min=0,\n",
    "                                 max=1.,\n",
    "                                 step=0.0001,\n",
    "                                 readout_format='.5f',\n",
    "                                 description='Ridge coefficient:',\n",
    "                                 style={'description_width': 'initial'},\n",
    "                                 continuous_update=False),\n",
    "    noise=ipywidgets.FloatSlider(value=0.1,\n",
    "                                 min=0,\n",
    "                                 max=0.5,\n",
    "                                 step=0.01,\n",
    "                                 readout_format='.2f',\n",
    "                                 description='Noise level:',\n",
    "                                 style={'description_width': 'initial'},\n",
    "                                 continuous_update=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF kernel classification with SVMs\n",
    "\n",
    "Illustration of binary classification with SVM using RBF kernels (i.e. Gaussian and Laplacian). You can observe the decision boundary for a few different data distributions and you can control the spread of the samples by moving the \"Variance\" slider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1f9712c41c4432a52236434624d254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=('blobs', 'circles', 'moons', 'xor', 'periodic')â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Our dataset and targets\n",
    "tol = 1e-1\n",
    "\n",
    "\n",
    "def laplacian_kernel(X, Y, gamma):\n",
    "    rows = X.shape[0]\n",
    "    cols = Y.shape[0]\n",
    "    K = np.zeros((rows, cols))\n",
    "    for col in range(cols):\n",
    "        dist = gamma * np.linalg.norm(X - Y[col, :], ord=1, axis=1)\n",
    "        K[:, col] = np.exp(-dist)\n",
    "    return K\n",
    "\n",
    "\n",
    "def kernelized_svm(dataset, kernel, n_samples, reg, bw, noise):\n",
    "    if dataset == 'blobs':\n",
    "        X, Y = datasets.make_blobs(n_samples=MAX_NUM_SAMPLES,\n",
    "                                   centers=2,\n",
    "                                   random_state=3,\n",
    "                                   cluster_std=10 * noise)\n",
    "    elif dataset == 'circles':\n",
    "        X, Y = datasets.make_circles(n_samples=MAX_NUM_SAMPLES,\n",
    "                                     factor=.5,\n",
    "                                     noise=noise,\n",
    "                                     random_state=42)\n",
    "    elif dataset == 'moons':\n",
    "        X, Y = datasets.make_moons(n_samples=MAX_NUM_SAMPLES,\n",
    "                                   noise=noise,\n",
    "                                   random_state=42)\n",
    "    elif dataset == 'xor':\n",
    "        np.random.seed(42)\n",
    "        step = int(MAX_NUM_SAMPLES / 4)\n",
    "\n",
    "        X = np.zeros((MAX_NUM_SAMPLES, 2))\n",
    "        Y = np.zeros(MAX_NUM_SAMPLES)\n",
    "\n",
    "        X[0 * step:1 * step, :] = noise * np.random.randn(step, 2)\n",
    "        Y[0 * step:1 * step] = 1\n",
    "        X[1 * step:2 *\n",
    "          step, :] = np.array([1, 1]) + noise * np.random.randn(step, 2)\n",
    "        Y[1 * step:2 * step] = 1\n",
    "\n",
    "        X[2 * step:3 *\n",
    "          step, :] = np.array([0, 1]) + noise * np.random.randn(step, 2)\n",
    "        Y[2 * step:3 * step] = -1\n",
    "        last_group_size = MAX_NUM_SAMPLES - 3 * step\n",
    "        X[3 * step:, :] = np.array([1, 0]) + noise * np.random.randn(last_group_size, 2)\n",
    "        Y[3 * step:] = -1\n",
    "\n",
    "    elif dataset == 'periodic':\n",
    "        np.random.seed(42)\n",
    "        step = int(MAX_NUM_SAMPLES / 4)\n",
    "\n",
    "        X = np.zeros((MAX_NUM_SAMPLES, 2))\n",
    "        Y = np.zeros(MAX_NUM_SAMPLES)\n",
    "\n",
    "        X[0 * step:1 * step, :] = noise * np.random.randn(step, 2)\n",
    "        Y[0 * step:1 * step] = 1\n",
    "        X[1 * step:2 *\n",
    "          step, :] = np.array([0, 2]) + noise * np.random.randn(step, 2)\n",
    "        Y[1 * step:2 * step] = 1\n",
    "\n",
    "        X[2 * step:3 *\n",
    "          step, :] = np.array([0, 1]) + noise * np.random.randn(step, 2)\n",
    "        Y[2 * step:3 * step] = -1\n",
    "        last_group_size = MAX_NUM_SAMPLES - 3 * step\n",
    "        X[3 * step:, :] = np.array([0, 3]) + noise * np.random.randn(last_group_size, 2)\n",
    "        Y[3 * step:] = -1\n",
    "\n",
    "    X = X[Y <= 1, :]\n",
    "    Y = Y[Y <= 1]\n",
    "    Y[Y == 0] = -1\n",
    "    \n",
    "    orig_X, orig_Y = deepcopy(X), deepcopy(Y)\n",
    "    np.random.seed(42)\n",
    "    idx = np.random.permutation(MAX_NUM_SAMPLES)\n",
    "    X, Y = X[idx][:n_samples], Y[idx][:n_samples]\n",
    "\n",
    "    # Add the 1 feature.\n",
    "    X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)\n",
    "    plot_support = False\n",
    "    gamma = np.power(10., -bw)\n",
    "    coef0 = 0\n",
    "    if kernel == 'Gaussian':\n",
    "        kernel = \"rbf\"\n",
    "    elif kernel == 'Laplacian':\n",
    "        kernel = lambda X, Y: laplacian_kernel(X, Y, gamma)\n",
    "        plot_support = False\n",
    "\n",
    "    classifier = svm.SVC(kernel=kernel,\n",
    "                         C=np.power(10., -reg),\n",
    "                         gamma=gamma,\n",
    "                         coef0=coef0,\n",
    "                         tol=tol,\n",
    "                         random_state=10)\n",
    "    classifier.fit(X, Y)\n",
    "\n",
    "    # plot the line, the points, and the nearest vectors to the plane\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    fig = plt.axes()\n",
    "    opt = {'marker': 'r*', 'label': '+'}\n",
    "    plot_data(X[np.where(Y == 1)[0], 0],\n",
    "              X[np.where(Y == 1)[0], 1],\n",
    "              fig=fig,\n",
    "              options=opt)\n",
    "    opt = {'marker': 'bo', 'label': '-'}\n",
    "    plot_data(X[np.where(Y == -1)[0], 0],\n",
    "              X[np.where(Y == -1)[0], 1],\n",
    "              fig=fig,\n",
    "              options=opt)\n",
    "\n",
    "    if plot_support:\n",
    "        plt.scatter(classifier.support_vectors_[:, 0],\n",
    "                    classifier.support_vectors_[:, 1],\n",
    "                    s=80,\n",
    "                    facecolors='none',\n",
    "                    edgecolors='k')\n",
    "\n",
    "    mins = np.min(orig_X, 0)\n",
    "    maxs = np.max(orig_X, 0)\n",
    "    x_min = mins[0] - 1\n",
    "    x_max = maxs[0] + 1\n",
    "    y_min = mins[1] - 1\n",
    "    y_max = maxs[1] + 1\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Xtest = np.c_[XX.ravel(), YY.ravel(), np.ones_like(XX.ravel())]\n",
    "    Z = classifier.decision_function(Xtest)\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.contourf(XX, YY, Z > 0, cmap=plt.cm.jet, alpha=0.3)\n",
    "    plt.contour(XX,\n",
    "                YY,\n",
    "                Z,\n",
    "                colors=['k', 'k', 'k'],\n",
    "                linestyles=['-'],\n",
    "                levels=[0])\n",
    "\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "\n",
    "\n",
    "def plot_data(X, Y, fig=None, options=dict()):\n",
    "    fig.plot(X,\n",
    "             Y,\n",
    "             options.get('marker', 'b*'),\n",
    "             label=options.get('label', 'Raw data'),\n",
    "             fillstyle=options.get('fillstyle', 'full'),\n",
    "             ms=options.get('size', 10))\n",
    "\n",
    "\n",
    "_ = interact(\n",
    "    kernelized_svm,\n",
    "    dataset=['blobs', 'circles', 'moons', 'xor', 'periodic'],\n",
    "    kernel=['Gaussian', 'Laplacian'],\n",
    "    n_samples=ipywidgets.IntSlider(value=100,\n",
    "                                 min=20,\n",
    "                                 max=MAX_NUM_SAMPLES,\n",
    "                                 step=10,\n",
    "                                 description='Number of samples:',\n",
    "                                 style={'description_width': 'initial'},\n",
    "                                 continuous_update=False),\n",
    "    reg=ipywidgets.FloatSlider(value=-3,\n",
    "                               min=-3,\n",
    "                               max=3,\n",
    "                               step=0.5,\n",
    "                               readout_format='.1f',\n",
    "                               description='Regularization 10^:',\n",
    "                               style={'description_width': 'initial'},\n",
    "                               continuous_update=False),\n",
    "    bw=ipywidgets.FloatSlider(value=-1,\n",
    "                              min=-3,\n",
    "                              max=3,\n",
    "                              step=0.1,\n",
    "                              readout_format='.1f',\n",
    "                              description='Bandwidth 10^:',\n",
    "                              style={'description_width': 'initial'},\n",
    "                              continuous_update=False),\n",
    "    noise=ipywidgets.FloatSlider(value=0.05,\n",
    "                                 min=0.01,\n",
    "                                 max=0.1,\n",
    "                                 step=0.01,\n",
    "                                 readout_format='.2f',\n",
    "                                 description='Variance:',\n",
    "                                 style={'description_width': 'initial'},\n",
    "                                 continuous_update=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

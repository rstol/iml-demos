{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Source: Alexandru Tifrea and Fanny Yang, 2021.\n",
    "# Based on an earlier version by Sebastian Curi and Andreas Krause.\n",
    "\n",
    "# Python Notebook Commands\n",
    "%reload_ext autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# General math and plotting modules.\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Widget and formatting modules\n",
    "import ipywidgets\n",
    "from ipywidgets import interact, interactive, interact_manual, fixed\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (10, 6)\n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "# Machine Learning library. \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "\n",
    "rcParams['figure.figsize'] = (15, 6)\n",
    "rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression with polynomial kernels\n",
    "\n",
    "In the following we show how the estimator depends on hyperparameters like the ridge coefficient or the the degree of the polynomial used for to define the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66651cf525a6457790c5e913008ad403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, continuous_update=False, description='Number of samples:', min=5, st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def true_regression_fun(X):\n",
    "#     return np.cos(1.5 * np.pi * X)\n",
    "    return np.cos(3 * np.pi * X)\n",
    "\n",
    "def poly_kernel_regression(n_samples, degree, l2_coef, noise):\n",
    "    np.random.seed(111)\n",
    "\n",
    "    X = np.sort(np.random.rand(n_samples))\n",
    "    y = true_regression_fun(X) + np.random.randn(n_samples) * noise\n",
    "\n",
    "    clf = make_pipeline(PolynomialFeatures(degree),\n",
    "                        Ridge(alpha=l2_coef, fit_intercept=False, solver=\"svd\"))\n",
    "    clf.fit(X[:, np.newaxis], y)\n",
    "    \n",
    "    X_test = np.linspace(-1, 2, 100)\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(17, 10))\n",
    "    ax1.plot(X_test, clf.predict(X_test[:, np.newaxis]), linestyle=\"-\", linewidth=3,\n",
    "             label=\"Model\")\n",
    "    ax1.plot(X_test, true_regression_fun(X_test), linestyle=\"--\", linewidth=3,\n",
    "             label=\"True function\")\n",
    "    ax1.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"y\")\n",
    "    ax1.set_xlim((0., 1.))\n",
    "    ax1.set_ylim((-2, 2))\n",
    "    ax1.legend(loc=\"lower left\")\n",
    "    \n",
    "    ax2.plot(np.arange(clf[\"ridge\"].coef_.shape[0]), np.fabs(clf[\"ridge\"].coef_), linewidth=3)\n",
    "    ax2.set_xlabel(\"Degree\")\n",
    "    ax2.set_ylabel(\"Abs. value of coefficient\")\n",
    "    plt.show()\n",
    "    \n",
    "interact(poly_kernel_regression, \n",
    "        n_samples=ipywidgets.IntSlider(value=20,\n",
    "                                       min=5,\n",
    "                                       max=100,\n",
    "                                       step=5,\n",
    "                                       description='Number of samples:',\n",
    "                                       style={'description_width': 'initial'},\n",
    "                                       continuous_update=False),\n",
    "        degree=ipywidgets.IntSlider(value=10,\n",
    "                                         min=1,\n",
    "                                         max=30,\n",
    "                                         step=1,\n",
    "                                         description='Polynomial Degree:',\n",
    "                                         style={'description_width': 'initial'},\n",
    "                                         continuous_update=False),\n",
    "         l2_coef=ipywidgets.FloatSlider(value=0.,\n",
    "                                      min=0,\n",
    "                                      max=0.01,\n",
    "                                      step=0.001,\n",
    "                                      readout_format='.3f',\n",
    "                                      description='Ridge coefficient:',\n",
    "                                      style={'description_width': 'initial'},\n",
    "                                      continuous_update=False),\n",
    "         noise=ipywidgets.FloatSlider(value=0.5,\n",
    "                                      min=0,\n",
    "                                      max=1,\n",
    "                                      step=0.1,\n",
    "                                      readout_format='.2f',\n",
    "                                      description='Noise level:',\n",
    "                                      style={'description_width': 'initial'},\n",
    "                                      continuous_update=False),);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression with RBF kernels\n",
    "\n",
    "In the following we show how the estimator depends on hyperparameters like the ridge coefficient or the bandwidth for two commonly used radial basis function kernels: the Gaussian and the Laplacian kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45986e2367ab4d7eafbbed9a0f502cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=30, continuous_update=False, description='Number of samples:', min=10, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rbf_kernel_regression(n_samples, kernel, bandwidth, l2_coef, noise):\n",
    "    np.random.seed(10)\n",
    "\n",
    "    X = np.sort(np.random.rand(n_samples))\n",
    "    y = true_regression_fun(X) + np.random.randn(n_samples) * noise\n",
    "\n",
    "    gamma = np.power(10., -bandwidth)\n",
    "    if kernel == 'Gaussian':\n",
    "      kernel = \"rbf\"\n",
    "    elif kernel == 'Laplacian':\n",
    "      kernel = \"laplacian\"\n",
    "    \n",
    "    clf = KernelRidge(alpha=l2_coef, kernel=kernel, gamma=gamma)\n",
    "    clf.fit(X[:, np.newaxis], y)\n",
    "\n",
    "\n",
    "    X_test = np.linspace(-1, 2, 100)\n",
    "    plt.plot(X_test, clf.predict(X_test[:, np.newaxis]), linestyle=\"-\", linewidth=3, \n",
    "             label=\"Model\")\n",
    "    plt.plot(X_test, true_regression_fun(X_test), linestyle=\"--\", linewidth=3, \n",
    "             label=\"True function\")\n",
    "    plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0., 1.))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()\n",
    "    \n",
    "interact(rbf_kernel_regression, \n",
    "         kernel=['Gaussian', 'Laplacian'], \n",
    "         bandwidth=ipywidgets.FloatSlider(value=-1,\n",
    "                                    min=-10,\n",
    "                                    max=10,\n",
    "                                    step=0.1,\n",
    "                                    readout_format='.1f',\n",
    "                                    description='Bandwidth 10^:',\n",
    "                                    style={'description_width': 'initial'},\n",
    "                                    continuous_update=False),  \n",
    "        n_samples=ipywidgets.IntSlider(value=30,\n",
    "                             min=10,\n",
    "                             max=100,\n",
    "                             step=10,\n",
    "                             description='Number of samples:',\n",
    "                             style={'description_width': 'initial'},\n",
    "                             continuous_update=False),\n",
    "        l2_coef=ipywidgets.FloatSlider(value=0.,\n",
    "                                    min=0,\n",
    "                                    max=1,\n",
    "                                    step=0.1,\n",
    "                                    readout_format='.2f',\n",
    "                                    description='Ridge coefficient:',\n",
    "                                    style={'description_width': 'initial'},\n",
    "                                    continuous_update=False),\n",
    "        noise=ipywidgets.FloatSlider(value=0.1,\n",
    "                                    min=0,\n",
    "                                    max=1,\n",
    "                                    step=0.01,\n",
    "                                    readout_format='.2f',\n",
    "                                    description='Noise level:',\n",
    "                                    style={'description_width': 'initial'},\n",
    "                                    continuous_update=False),);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF kernel classification with SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ea16d8f2154f8aba11016031ae6d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=('blobs', 'circles', 'moons', 'xor', 'periodic')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Our dataset and targets\n",
    "n_samples = 20  # Number of points per class\n",
    "tol = 1e-1\n",
    "\n",
    "def laplacian_kernel(X, Y, gamma):\n",
    "    rows = X.shape[0]\n",
    "    cols = Y.shape[0]\n",
    "    K = np.zeros((rows, cols))\n",
    "    for col in range(cols):\n",
    "        dist = gamma * np.linalg.norm(X - Y[col, :], ord=1, axis=1)\n",
    "        K[:, col] = np.exp(-dist)\n",
    "    return K\n",
    "\n",
    "def kernelized_svm(dataset, kernel, reg, bw, noise):\n",
    "    if dataset == 'blobs':\n",
    "        X, Y = datasets.make_blobs(n_samples=n_samples, centers=2, random_state=3, cluster_std=10*noise)\n",
    "    elif dataset == 'circles':\n",
    "        X, Y = datasets.make_circles(n_samples=n_samples, factor=.5, noise=noise, random_state=42)\n",
    "    elif dataset == 'moons':\n",
    "        X, Y = datasets.make_moons(n_samples=n_samples, noise=noise, random_state=42)\n",
    "    elif dataset == 'xor':\n",
    "        np.random.seed(42)\n",
    "        step = int(n_samples/4)\n",
    "        \n",
    "        X = np.zeros((n_samples, 2))\n",
    "        Y = np.zeros(n_samples)\n",
    "        \n",
    "        X[0*step:1*step, :] = noise * np.random.randn(step, 2)\n",
    "        Y[0*step:1*step] = 1\n",
    "        X[1*step:2*step, :] = np.array([1, 1]) + noise * np.random.randn(step, 2)\n",
    "        Y[1*step:2*step] = 1\n",
    "        \n",
    "        X[2*step:3*step, :] = np.array([0, 1]) + noise * np.random.randn(step, 2)\n",
    "        Y[2*step:3*step] = -1\n",
    "        X[3*step:4*step, :] = np.array([1, 0]) + noise * np.random.randn(step, 2)\n",
    "        Y[3*step:4*step] = -1\n",
    "    \n",
    "    elif dataset == 'periodic':\n",
    "        np.random.seed(42)\n",
    "        step = int(n_samples/4)\n",
    "        \n",
    "        X = np.zeros((n_samples, 2))\n",
    "        Y = np.zeros(n_samples)\n",
    "        \n",
    "        X[0*step:1*step, :] = noise * np.random.randn(step, 2)\n",
    "        Y[0*step:1*step] = 1\n",
    "        X[1*step:2*step, :] = np.array([0, 2]) + noise * np.random.randn(step, 2)\n",
    "        Y[1*step:2*step] = 1\n",
    "        \n",
    "        X[2*step:3*step, :] = np.array([0, 1]) + noise * np.random.randn(step, 2)\n",
    "        Y[2*step:3*step] = -1\n",
    "        X[3*step:4*step, :] = np.array([0, 3]) + noise * np.random.randn(step, 2)\n",
    "        Y[3*step:4*step] = -1\n",
    "        \n",
    "    X = X[Y <= 1, :]\n",
    "    Y = Y[Y <=1 ]\n",
    "    Y[Y==0] = -1\n",
    "        \n",
    "    # Add the 1 feature.  \n",
    "    X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)\n",
    "    plot_support = False\n",
    "    gamma = np.power(10., -bw)\n",
    "    coef0 = 0\n",
    "    if kernel == 'Gaussian':\n",
    "      kernel = \"rbf\"\n",
    "    elif kernel == 'Laplacian':\n",
    "      kernel = lambda X, Y: laplacian_kernel(X, Y, gamma)\n",
    "      plot_support = False\n",
    "\n",
    "    classifier = svm.SVC(kernel=kernel, C=np.power(10., -reg), gamma=gamma, coef0=coef0, tol=tol)\n",
    "    classifier.fit(X, Y)\n",
    "\n",
    "    # plot the line, the points, and the nearest vectors to the plane\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    fig = plt.axes()\n",
    "    opt = {'marker': 'r*', 'label': '+'}\n",
    "    plot_data(X[np.where(Y == 1)[0], 0], X[np.where(Y == 1)[0], 1], fig=fig, options=opt)\n",
    "    opt = {'marker': 'bo', 'label': '-'}\n",
    "    plot_data(X[np.where(Y == -1)[0], 0], X[np.where(Y == -1)[0], 1], fig=fig, options=opt)\n",
    "    \n",
    "    if plot_support:\n",
    "        plt.scatter(classifier.support_vectors_[:, 0], classifier.support_vectors_[:, 1], s=80,\n",
    "                    facecolors='none', edgecolors='k')\n",
    "\n",
    "    mins = np.min(X, 0)\n",
    "    maxs = np.max(X, 0)\n",
    "    x_min = mins[0] - 1\n",
    "    x_max = maxs[0] + 1\n",
    "    y_min = mins[1] - 1\n",
    "    y_max = maxs[1] + 1\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]  \n",
    "    Xtest = np.c_[XX.ravel(), YY.ravel(), np.ones_like(XX.ravel())]\n",
    "    Z = classifier.decision_function(Xtest)\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.contourf(XX, YY, Z > 0, cmap=plt.cm.jet, alpha=0.3)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['-'], levels=[0])\n",
    "\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    \n",
    "    \n",
    "def plot_data(X, Y, fig=None, options=dict()):\n",
    "    fig.plot(X, Y, options.get('marker', 'b*'), \n",
    "        label=options.get('label', 'Raw data'),\n",
    "        fillstyle=options.get('fillstyle', 'full'),\n",
    "        ms=options.get('size', 10))\n",
    "\n",
    "\n",
    "interact(kernelized_svm, \n",
    "         dataset=['blobs', 'circles', 'moons', 'xor', 'periodic'],\n",
    "         kernel=['Gaussian', 'Laplacian'], \n",
    "         reg=ipywidgets.FloatSlider(value=-3,\n",
    "                                    min=-3,\n",
    "                                    max=3,\n",
    "                                    step=0.5,\n",
    "                                    readout_format='.1f',\n",
    "                                    description='Regularization 10^:',\n",
    "                                    style={'description_width': 'initial'},\n",
    "                                    continuous_update=False),\n",
    "         bw=ipywidgets.FloatSlider(value=-1,\n",
    "                                    min=-3,\n",
    "                                    max=3,\n",
    "                                    step=0.1,\n",
    "                                    readout_format='.1f',\n",
    "                                    description='Bandwidth 10^:',\n",
    "                                    style={'description_width': 'initial'},\n",
    "                                    continuous_update=False),  \n",
    "         noise=ipywidgets.FloatSlider(value=0.05,\n",
    "                                    min=0.01,\n",
    "                                    max=0.3,\n",
    "                                    step=0.01,\n",
    "                                    readout_format='.2f',\n",
    "                                    description='Noise level:',\n",
    "                                    style={'description_width': 'initial'},\n",
    "                                    continuous_update=False),);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T12:49:02.243814Z",
     "start_time": "2021-05-18T12:49:02.153982Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Code source: Sebastian Curi and Andreas Krause, based on Jaques Grobler (sklearn demos).\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# We start importing some modules and running some magic commands\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# General math and plotting modules.\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import erfinv\n",
    "from scipy import linalg\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "\n",
    "# Project files.\n",
    "from utilities.util import gradient_descent\n",
    "from utilities.classifiers import Logistic\n",
    "from utilities.regularizers import L2Regularizer\n",
    "from utilities.load_data import polynomial_data, linear_separable_data\n",
    "from utilities import plot_helpers\n",
    "from utilities.widgets import noise_widget, n_components_widget, min_prob_widget\n",
    "\n",
    "# Widget and formatting modules\n",
    "import IPython\n",
    "import ipywidgets\n",
    "from ipywidgets import interact, interactive, interact_manual, fixed\n",
    "from matplotlib import rcParams\n",
    "import matplotlib as mpl \n",
    "\n",
    "# If in your browser the figures are not nicely vizualized, change the following line. \n",
    "rcParams['figure.figsize'] = (10, 5)\n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "# Machine Learning library. \n",
    "import torch \n",
    "import torch.jit\n",
    "import torch.nn as nn \n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T12:49:02.779451Z",
     "start_time": "2021-05-18T12:49:02.727446Z"
    }
   },
   "outputs": [],
   "source": [
    "class GMM(object):\n",
    "    def __init__(self, weights, means, scales):\n",
    "        self.num_centers = len(weights)\n",
    "        self.weights = weights / np.sum(weights)\n",
    "        self.means = means\n",
    "        self.scales = scales \n",
    "    \n",
    "    def sample(self, batch_size=1):\n",
    "        centers = np.random.choice(self.num_centers, batch_size, p=self.weights)\n",
    "        eps = np.random.randn(batch_size)\n",
    "        return self.means[centers] + eps * self.scales[centers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T12:49:03.611109Z",
     "start_time": "2021-05-18T12:49:03.548876Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_gmm(true_model, sampling_model, discriminator=None, title=None):\n",
    "    gaussians = [norm(mean, scale) for mean, scale in zip(true_model.means, true_model.scales)]\n",
    "    scale = sum(true_model.weights)\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    X = np.linspace(-1.25, 1.25, 1000)\n",
    "    y = np.zeros_like(X)\n",
    "    for i, (weight, gaussian) in enumerate(zip(true_model.weights, gaussians)):\n",
    "        y += weight * gaussian.pdf(X) / scale\n",
    "\n",
    "    ax.plot(X, y, label='Exact PDF')\n",
    "    try:\n",
    "        ax.hist(sampling_model.sample(10000), bins=100, density=True, label='Samples')\n",
    "    except ValueError:\n",
    "        ax.hist(sampling_model.sample(10000)[0][:, 0], bins=100, density=True, label='Samples')\n",
    "    \n",
    "    ax.plot([], [], color=\"g\", label=\"Prob[Real]\")\n",
    "    if discriminator is not None:\n",
    "        ax2 = ax.twinx()  \n",
    "        ax2.plot(X, discriminator(torch.tensor(X).unsqueeze(-1).float()).detach().numpy(), color=\"g\")\n",
    "        ax2.set_ylim([0, 1])\n",
    "        ax2.set_ylabel(\"Probability\")\n",
    "\n",
    "    ax.legend(loc='best')\n",
    "    \n",
    "    \n",
    "    # This is hard coded for the GMMs in the next cells. \n",
    "    if true_model.num_centers == 1:\n",
    "        ax.set_ylim([0, 3.0])\n",
    "        ax.set_xlim([-0.25, 1.25])\n",
    "    else:\n",
    "        ax.set_ylim([0, 5.0])\n",
    "        ax.set_xlim([-1.25, 1.25])\n",
    "        \n",
    "    ax.set_title(title)\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    IPython.display.display(fig)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T12:49:09.409704Z",
     "start_time": "2021-05-18T12:49:09.343315Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Given a random input, produce a random output.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int, output_dim: int, noise='uniform'):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.noise = noise\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, 15),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(15, output_dim),\n",
    "            nn.Tanh()  # Distribution is bounded between -1 and 1.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "    def rsample(self, batch_size=1):\n",
    "        \"\"\"Get a differentiable sample of the generator model.\"\"\"\n",
    "        if self.noise == 'uniform':\n",
    "            noise = torch.rand(batch_size, self.input_dim)\n",
    "\n",
    "        elif self.noise == 'normal':\n",
    "            noise = torch.randn(batch_size, self.input_dim)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        return self(noise).squeeze(-1)\n",
    "\n",
    "    def sample(self, batch_size=1):\n",
    "        \"\"\"Get a sample of the generator model.\"\"\"\n",
    "        return self.rsample(batch_size).detach()\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminate if true from fake samples.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, 25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(25, 1),\n",
    "            nn.Sigmoid()  # Output is bounded between 0 and 1.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T12:42:43.476787Z",
     "start_time": "2021-05-18T12:42:43.436593Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, true_model, generator_optimizer, discriminator_optimizer, \n",
    "              num_iter, discriminator_loss, generator_loss, plot_freq=1000, batch_size=64):\n",
    "    loss = nn.BCELoss()\n",
    "    for i in range(num_iter):\n",
    "        true_data = torch.tensor(true_model.sample(batch_size)).float().unsqueeze(-1)\n",
    "        fake_data = generator.rsample(batch_size).unsqueeze(-1)\n",
    "        # equivalently, fake_data = generator(torch.randn(batch_size, code_size)).squeeze()\n",
    "\n",
    "        true_label = torch.full((batch_size,), 1.)\n",
    "        fake_label = torch.full((batch_size,), 0.)\n",
    "\n",
    "        ###################################################################################\n",
    "        # Update G network: maximize log(D(G(z)))                                         #\n",
    "        ###################################################################################\n",
    "        generator_optimizer.zero_grad()\n",
    "        loss_g = loss(discriminator(fake_data), true_label)  # true label.\n",
    "        loss_g.backward()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        generator_loss.append(loss_g.item())\n",
    "\n",
    "        ###################################################################################\n",
    "        # Update D network: maximize log(D(x)) + log(1 - D(G(z)))                         #\n",
    "        ###################################################################################\n",
    "        discriminator_optimizer.zero_grad()\n",
    "\n",
    "        # train on true data.\n",
    "        loss_d_true = loss(discriminator(true_data), true_label)\n",
    "        loss_d_true.backward()\n",
    "\n",
    "        # train on fake data.\n",
    "        loss_d_fake = loss(discriminator(fake_data.detach()), fake_label)\n",
    "        loss_d_fake.backward()\n",
    "\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        loss_d = loss_d_true + loss_d_fake\n",
    "        discriminator_loss.append(loss_d.item())\n",
    "\n",
    "        if plot_freq and i % plot_freq == 0:\n",
    "            ax = plot_gmm(true_model, generator, discriminator, f\"Episode {i}\")\n",
    "    \n",
    "    return discriminator_loss, generator_loss\n",
    "\n",
    "\n",
    "def train_gan_interactive(num_iter, true_model, noise_model, noise_dim, generator_lr, discriminator_lr, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    generator = Generator(input_dim=noise_dim, output_dim=1, noise=noise_model)\n",
    "    discriminator = Discriminator(input_dim=1)\n",
    "    \n",
    "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=generator_lr, betas=(0.5, 0.999))\n",
    "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=discriminator_lr, betas=(0.5, 0.99))\n",
    "\n",
    "    discriminator_loss, generator_loss = [], []\n",
    "    try:\n",
    "        train_gan(generator, discriminator, true_model, generator_optimizer, discriminator_optimizer, num_iter, discriminator_loss, generator_loss)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    plot_gmm(true_model, generator, discriminator, \"Final Generator Model\")\n",
    "    plt.plot(generator_loss, label='Generator Loss')\n",
    "    plt.plot(discriminator_loss, label='Discriminator Loss')\n",
    "    plt.xlabel('Iteration Number')\n",
    "    plt.ylabel(' Loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN's for fitting a Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T12:42:46.776669Z",
     "start_time": "2021-05-18T12:42:46.363292Z"
    }
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 8)\n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "gaussian_model = GMM(weights=np.array([1.]),means=np.array([0.5]), scales=np.array([0.2])) \n",
    "plot_gmm(gaussian_model, gaussian_model, title='Exact Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T12:48:54.907369Z",
     "start_time": "2021-05-18T12:48:54.832885Z"
    }
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 8)\n",
    "rcParams['font.size'] = 16\n",
    "num_iter = 15000\n",
    "interact_manual(lambda noise_model, noise_dim, generator_lr, discriminator_lr: train_gan_interactive(\n",
    "    num_iter, gaussian_model, noise_model, noise_dim, generator_lr, discriminator_lr, seed=2),\n",
    "                noise_model=ipywidgets.Dropdown(options=['uniform', 'normal'], value='normal', description='Noise model:', style={'description_width': 'initial'}, continuous_update=False),\n",
    "                noise_dim=ipywidgets.IntSlider(min=4, max=10, value=2, description='Noise dimension:', style={'description_width': 'initial'}, continuous_update=False),\n",
    "                generator_lr=ipywidgets.FloatLogSlider(value=1e-4, min=-6, max=0, description=\"Generator lr\", style={'description_width': 'initial'}, continuous_update=False),\n",
    "                discriminator_lr=ipywidgets.FloatLogSlider(value=1e-3, min=-6, max=0, description=\"Discriminator lr\", style={'description_width': 'initial'}, continuous_update=False),\n",
    "               );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN's for fitting a GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T12:43:02.672548Z",
     "start_time": "2021-05-18T12:43:02.261916Z"
    }
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 8)\n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "gmm_model = GMM(weights=np.array([0.3, 0.5, 0.2]),\n",
    "                 means=np.array([-3., 0., 2.]) / 5,\n",
    "                 scales=np.array([0.5, 1.0, 0.1]) / 5)\n",
    "plot_gmm(gmm_model, gmm_model, title='Exact Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T12:43:04.488494Z",
     "start_time": "2021-05-18T12:43:04.418044Z"
    }
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 8)\n",
    "rcParams['font.size'] = 16\n",
    "num_iter = 15000\n",
    "interact_manual(lambda noise_model, noise_dim, generator_lr, discriminator_lr: train_gan_interactive(\n",
    "    num_iter, gmm_model, noise_model, noise_dim, generator_lr, discriminator_lr),\n",
    "                noise_model=ipywidgets.Dropdown(options=['uniform', 'normal'], value='normal', description='Noise model:', style={'description_width': 'initial'}, continuous_update=False),\n",
    "                noise_dim=ipywidgets.IntSlider(min=1, max=10, value=8, description='Noise dimension:', style={'description_width': 'initial'}, continuous_update=False),\n",
    "                generator_lr=ipywidgets.FloatLogSlider(value=1e-4, min=-6, max=0, description=\"Generator lr\", style={'description_width': 'initial'}, continuous_update=False),\n",
    "                discriminator_lr=ipywidgets.FloatLogSlider(value=1e-3, min=-6, max=0, description=\"Discriminator lr\", style={'description_width': 'initial'}, continuous_update=False),\n",
    "               );\n",
    "# Generator lr <= 1e-5 shows mode collapse\n",
    "# Generator lr >= 1e-3 shows oscillation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T12:43:39.483706Z",
     "start_time": "2021-05-18T12:43:38.990062Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision \n",
    "from torchvision import transforms\n",
    "\n",
    "MNIST = True \n",
    "torchvision.datasets.MNIST.resources = [\n",
    "    ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz', 'f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n",
    "    ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz', 'd53e105ee54ea40749a09fcbcd1e9432'),\n",
    "    ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz', '9fb629c4189551a2d022fa330f9573f3'),\n",
    "    ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz', 'ec29112dd5afa0611ce80d1b7f02629c')\n",
    "        ]\n",
    "\n",
    "if MNIST:\n",
    "    from mnist_dcgan.dcgan import Discriminator, Generator\n",
    "    tranforms_ = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5, ))])\n",
    "    dataset = torchvision.datasets.MNIST('../data', train=True, download=True, transform=tranforms_)\n",
    "    d_path = 'mnist_dcgan/weights/netD_epoch_99.pth'\n",
    "    g_path = 'mnist_dcgan/weights/netG_epoch_99.pth'\n",
    "\n",
    "else:\n",
    "    from cifar10_dcgan.dcgan import Discriminator, Generator\n",
    "\n",
    "    transforms_ = transforms.Compose([\n",
    "                                   transforms.Resize(64),\n",
    "                                   transforms.ToTensor(),\n",
    "#                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               ])\n",
    "    dataset = torchvision.datasets.CIFAR10('../data', train=True, download=True, transform=tranforms_)\n",
    "    d_path = 'cifar10_dcgan/weights/netD_epoch_199.pth'\n",
    "    g_path = 'cifar10_dcgan/weights/netG_epoch_199.pth'\n",
    "    \n",
    "N = len(dataset)\n",
    "\n",
    "D = Discriminator(ngpu=0).eval()\n",
    "G = Generator(ngpu=0).eval()\n",
    "\n",
    "\n",
    "# load weights\n",
    "\n",
    "# load weights\n",
    "D.load_state_dict(torch.load(d_path, map_location=torch.device('cpu')))\n",
    "G.load_state_dict(torch.load(g_path, map_location=torch.device('cpu')))\n",
    "\n",
    "batch_size = 1\n",
    "latent_size = 100\n",
    "\n",
    "def sample_image():\n",
    "    true_button = ipywidgets.Button(description=\"True Image\")\n",
    "    fake_button = ipywidgets.Button(description=\"Fake Image\")\n",
    "    reset_button = ipywidgets.Button(description=\"Resample Image\")\n",
    "    hint_button = ipywidgets.Button(description=\"Show Hint\")\n",
    "    \n",
    "    def print_string(correct, choice, alternative):\n",
    "        if correct:\n",
    "            print(f\"Correct! The image was {choice}\")\n",
    "        else:\n",
    "            print(f\"Incorrect: The image was {alternative}\")\n",
    "            \n",
    "    def is_true(b):\n",
    "        global true_image\n",
    "        print_string(true_image == 1, \"Real\", \"Fake\")\n",
    "        display(reset_button)\n",
    "        \n",
    "    def is_fake(b):\n",
    "        global true_image\n",
    "        print_string(true_image == 0, \"Fake\", \"Real\")\n",
    "        display(reset_button)\n",
    "        \n",
    "    def hint(b):\n",
    "        global probs \n",
    "        print(f\"The discriminator thinks it is real with {probs.item():.2f} probability\")\n",
    "        \n",
    "    def reset(b):\n",
    "        IPython.display.clear_output(wait=True)\n",
    "        plt.close()\n",
    "        plt.figure(figsize = (3,3)) \n",
    "        \n",
    "        global true_image, probs\n",
    "        \n",
    "        noise = torch.randn(batch_size, latent_size, 1, 1)\n",
    "        true_image = np.random.choice(2)\n",
    "\n",
    "        if true_image:\n",
    "            image = dataset[np.random.choice(N)][0].unsqueeze(0)\n",
    "        else:\n",
    "            image = G(noise)\n",
    "        probs = D(image)\n",
    "\n",
    "        image_np = image.cpu().detach().numpy()\n",
    "        if MNIST:\n",
    "            plt.imshow(image_np[0, 0], cmap=\"gray\")\n",
    "        else:   \n",
    "            plt.imshow(image_np[0].transpose(1, 2, 0), interpolation=\"bilinear\")\n",
    "    \n",
    "        display(true_button)\n",
    "        display(fake_button)\n",
    "        display(hint_button)\n",
    "\n",
    "\n",
    "    true_button.on_click(is_true)\n",
    "    fake_button.on_click(is_fake)\n",
    "    hint_button.on_click(hint)\n",
    "    reset_button.on_click(reset)\n",
    "    \n",
    "    reset(None)\n",
    "    \n",
    "interact(sample_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T12:44:15.970317Z",
     "start_time": "2021-05-18T12:43:52.523470Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "num_images = 32\n",
    "use_gpu = False\n",
    "gan = 'PGAN'\n",
    "model_name = 'celebAHQ-512'\n",
    "model_name = 'celeba'\n",
    "\n",
    "\n",
    "model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', gan, model_name=model_name, pretrained=True, useGPU=use_gpu)\n",
    "\n",
    "noise, _ = model.buildNoiseData(num_images)\n",
    "with torch.no_grad():\n",
    "    generated_images = model.test(noise)\n",
    "\n",
    "# let's plot these images using torchvision and matplotlib\n",
    "\n",
    "grid = torchvision.utils.make_grid(generated_images.clamp(min=-1, max=1), scale_each=True, normalize=True)\n",
    "plt.imshow(grid.permute(1, 2, 0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

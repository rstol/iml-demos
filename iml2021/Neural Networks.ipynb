{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "Neural networks are a way of parametrizing non-linear functions. On a very basic level, they are formed by a composition of non-linear function. The functions is defined with a layered architecture. The mapping from the input layer to the output layer is performed via hidden layers. Each layer $k$ produces an output $z_k$ that is a non-linear function of a weighted combination of the outputs of the previous layer, $z_k = g_k(W_k z_{k-1})$. \n",
    "\n",
    "Once the architecture and the activation functions $g_k(\\cdot)$ are defined, the weights $W_k$ are trained. If all the functions $g_k$ are (sub)-differentiable then, via the chain rule, gradients exist and can be computed. The weights are trained via different variants of gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T13:26:09.133391Z",
     "start_time": "2022-04-04T13:26:07.915684Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import interact, interactive, interact_manual, fixed\n",
    "import IPython\n",
    "from utilities import plot_helpers\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (10, 5)  # Change this if figures look ugly. \n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Demo\n",
    "\n",
    "Neural network training has a lot of hyperparameters. Architecture, learning rate, batch size, optimization algorithm, random seed are just a few of them. Because of non-convexity, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T13:26:09.576436Z",
     "start_time": "2022-04-04T13:26:09.201893Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_samples = 200\n",
    "\n",
    "rcParams['figure.figsize'] = (10, 5)  # Change this if figures look ugly. \n",
    "rcParams['font.size'] = 16\n",
    "def mlp(dataset, hidden_layer_sizes, activation, solver, reg, noise):\n",
    "    np.random.seed(42)\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, \n",
    "                               activation=activation,\n",
    "                               solver=solver,\n",
    "#                                max_iter=n_iter, \n",
    "                               alpha=np.power(10., reg),\n",
    "#                                verbose=10, \n",
    "#                                tol=1e-4, \n",
    "                               random_state=1,\n",
    "                               learning_rate_init=.1)\n",
    "\n",
    "    if dataset is 'blobs':\n",
    "        X, Y = datasets.make_blobs(n_samples=n_samples, centers=2, random_state=3, cluster_std=10*noise)\n",
    "    elif dataset is 'circles':\n",
    "        X, Y = datasets.make_circles(n_samples=n_samples, factor=.5, noise=noise, random_state=42)\n",
    "    elif dataset is 'moons':\n",
    "        X, Y = datasets.make_moons(n_samples=n_samples, noise=noise, random_state=42)\n",
    "    elif dataset == 'xor':\n",
    "        np.random.seed(42)\n",
    "        step = int(n_samples/4)\n",
    "        \n",
    "        X = np.zeros((n_samples, 2))\n",
    "        Y = np.zeros(n_samples)\n",
    "        \n",
    "        X[0*step:1*step, :] = noise * np.random.randn(step, 2)\n",
    "        Y[0*step:1*step] = 1\n",
    "        X[1*step:2*step, :] = np.array([1, 1]) + noise * np.random.randn(step, 2)\n",
    "        Y[1*step:2*step] = 1\n",
    "        \n",
    "        X[2*step:3*step, :] = np.array([0, 1]) + noise * np.random.randn(step, 2)\n",
    "        Y[2*step:3*step] = -1\n",
    "        X[3*step:4*step, :] = np.array([1, 0]) + noise * np.random.randn(step, 2)\n",
    "        Y[3*step:4*step] = -1\n",
    "    \n",
    "    elif dataset == 'periodic':\n",
    "        \n",
    "        step = int(n_samples/4)\n",
    "        \n",
    "        X = np.zeros((n_samples, 2))\n",
    "        Y = np.zeros(n_samples)\n",
    "        \n",
    "        X[0*step:1*step, :] = noise * np.random.randn(step, 2)\n",
    "        Y[0*step:1*step] = 1\n",
    "        X[1*step:2*step, :] = np.array([0, 2]) + noise * np.random.randn(step, 2)\n",
    "        Y[1*step:2*step] = 1\n",
    "        \n",
    "        X[2*step:3*step, :] = np.array([0, 1]) + noise * np.random.randn(step, 2)\n",
    "        Y[2*step:3*step] = -1\n",
    "        X[3*step:4*step, :] = np.array([0, 3]) + noise * np.random.randn(step, 2)\n",
    "        Y[3*step:4*step] = -1\n",
    "    \n",
    "    X = X[Y <= 1, :]\n",
    "    Y = Y[Y <=1 ]\n",
    "    Y[Y==0] = -1\n",
    "        \n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.4)\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    print(classifier.score(X_test, y_test))\n",
    "    \n",
    "    \n",
    "    # plot the line, the points, and the nearest vectors to the plane\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    fig = plt.axes()\n",
    "    opt = {'marker': 'r*', 'label': '+'}\n",
    "    plot_helpers.plot_data(X[np.where(Y == 1)[0], 0], X[np.where(Y == 1)[0], 1], fig=fig, options=opt)\n",
    "    opt = {'marker': 'bs', 'label': '-'}\n",
    "    plot_helpers.plot_data(X[np.where(Y == -1)[0], 0], X[np.where(Y == -1)[0], 1], fig=fig, options=opt)\n",
    "\n",
    "    mins = np.min(X, 0)\n",
    "    maxs = np.max(X, 0)\n",
    "    x_min = mins[0] - 1\n",
    "    x_max = maxs[0] + 1\n",
    "    y_min = mins[1] - 1\n",
    "    y_max = maxs[1] + 1\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]  \n",
    "    Xplot = np.c_[XX.ravel(), YY.ravel()]\n",
    "    if hasattr(classifier, \"decision_function\"):\n",
    "        Z = classifier.decision_function(Xplot)\n",
    "    else:\n",
    "        Z = classifier.predict_proba(Xplot)[:, 1]\n",
    "            \n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    # plt.figure(fignum, figsize=(4, 3))\n",
    "    # Put the result into a color plot\n",
    "    plt.contourf(XX, YY, Z, cmap=plt.cm.jet, alpha=.3)\n",
    "    \n",
    "    \n",
    "interact(mlp, \n",
    "        dataset=['blobs', 'circles', 'moons', 'xor', 'periodic'],\n",
    "        activation=['relu', 'logistic', 'identity', 'tanh'],\n",
    "        solver=[ 'adam','lbfgs', 'sgd'],\n",
    "        hidden_layer_sizes=[(4, ), (100, ), (50, 50), (100, 100), (50, 50, 50), (100, 100, 100)],\n",
    "        reg=ipywidgets.FloatSlider(value=-3,\n",
    "                                    min=-3,\n",
    "                                    max=3,\n",
    "                                    step=0.1,\n",
    "                                    readout_format='.1f',\n",
    "                                    description='reg 10^:',\n",
    "                                    style={'description_width': 'initial'},\n",
    "                                    continuous_update=False),\n",
    "        noise=ipywidgets.FloatSlider(value=0.05,\n",
    "                                    min=0.01,\n",
    "                                    max=0.3,\n",
    "                                    step=0.01,\n",
    "                                    readout_format='.2f',\n",
    "                                    description='noise:',\n",
    "                                    style={'description_width': 'initial'},\n",
    "                                    continuous_update=False),  \n",
    "        );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T13:26:12.322481Z",
     "start_time": "2022-04-04T13:26:11.603690Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, dropout=True):\n",
    "        \"\"\"Here you define the network.\"\"\"\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Sequential(nn.Linear(28 * 28, 100), nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(100, 100), nn.ReLU())\n",
    "        if dropout:\n",
    "            self.fc3 = nn.Sequential(nn.Dropout(), nn.Linear(100, 10))\n",
    "        else:\n",
    "            self.fc3 = nn.Linear(100, 10)\n",
    "            \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Here you compute the forwards pass.\"\"\"\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x \n",
    "    \n",
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self, dropout=True):\n",
    "        \"\"\"Here you define the network.\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.c1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride=2)\n",
    "        )\n",
    "        self.c2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Sequential(nn.Linear(256, 120), nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(120, 84), nn.ReLU())\n",
    "        if dropout:\n",
    "            self.fc3 = nn.Sequential(nn.Dropout(), nn.Linear(84, 10))\n",
    "        else:\n",
    "            self.fc3 = nn.Linear(84, 10)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \"\"\"Here you compute the forwards pass.\"\"\"\n",
    "        x = self.c1(x)\n",
    "        x = self.c2(x)\n",
    "        x = x.view(-1, 256)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T09:38:03.307597Z",
     "start_time": "2022-04-01T09:38:03.305197Z"
    }
   },
   "source": [
    "## Define datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T13:26:54.911821Z",
     "start_time": "2022-04-04T13:26:48.772194Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128 \n",
    "torchvision.datasets.MNIST.resources = [\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz', 'f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz', 'd53e105ee54ea40749a09fcbcd1e9432'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz', '9fb629c4189551a2d022fa330f9573f3'),\n",
    "            ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz', 'ec29112dd5afa0611ce80d1b7f02629c')\n",
    "        ]\n",
    "\n",
    "t2pil = transforms.ToPILImage()\n",
    "tranforms_ = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5, ))])\n",
    "train_set = torchvision.datasets.MNIST('../data', train=True, download=True, transform=tranforms_)\n",
    "test_set = torchvision.datasets.MNIST('../data', train=False, download=True, transform=tranforms_)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T09:38:59.333059Z",
     "start_time": "2022-04-01T09:38:59.330610Z"
    }
   },
   "source": [
    "## Train! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T13:27:57.929306Z",
     "start_time": "2022-04-04T13:27:57.838909Z"
    }
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 10)\n",
    "\n",
    "\n",
    "def compute_accuracy(output, true_label):\n",
    "    return (output.argmax(-1) == true_label).double().mean()\n",
    "\n",
    "def evaluate_step(network, criterion, data, target):\n",
    "    output = network(data)\n",
    "    loss = criterion(output, target)\n",
    "    accuracy = compute_accuracy(output, target)\n",
    "    return loss.item(), accuracy.item()\n",
    "\n",
    "def train_step(network, criterion, optimizer, data, target):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    accuracy = compute_accuracy(output, target)\n",
    "    return loss.item(), accuracy.item()\n",
    "        \n",
    "def evaluate_epoch(network, data_loader, criterion):\n",
    "    network.eval()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for data, target in test_loader:\n",
    "        loss, accuracy = evaluate_step(network, criterion, data, target)\n",
    "        losses.append(loss)\n",
    "        accuracies.append(accuracy)\n",
    "    losses = torch.tensor(losses)\n",
    "    accuracies = torch.tensor(accuracies)\n",
    "    return losses.mean(), accuracies.mean()\n",
    "\n",
    "def plot_losses(x_train, train_losses, x_test, test_losses, ax):\n",
    "    ax.plot(x_train, train_losses, label=\"Train Loss\")\n",
    "    ax.plot(x_test, test_losses, label=\"Test Loss\")\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlim([0, 2000])\n",
    "    ax.set_ylim([0, 2.5])\n",
    "    ax.legend(loc=\"north west\")\n",
    "\n",
    "    \n",
    "def plot_accuracies(x_train, train_accuracies, x_test, test_accuracies, ax):\n",
    "    ax.plot(x_train, train_accuracies, label=\"Train Accuracy\")\n",
    "    ax.plot(x_test, test_accuracies, label=\"Test Accuracy\")\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_xlim([0, 2000])\n",
    "    ax.set_ylim([0, 1.0])\n",
    "    ax.legend(loc=\"north west\")\n",
    "    \n",
    "def resample(network, dataloader, ax_image, ax_labels):\n",
    "    for data, label in dataloader:\n",
    "        break \n",
    "    idx = np.random.randint(data.shape[0])\n",
    "    im = data[idx]\n",
    "    true_label = label[idx]\n",
    "    out = network(data)[idx]\n",
    "    ax_image.imshow(t2pil(im), cmap='Greys')\n",
    "    ax_image.set_xticklabels(\"\")\n",
    "    ax_image.set_yticklabels(\"\")\n",
    "\n",
    "    ax_labels.bar(np.arange(0, 10), nn.functional.softmax(out).detach().numpy())\n",
    "    ax_labels.set_xticks(np.arange(0, 10))\n",
    "    ax_labels.set_xticklabels(np.arange(0, 10))\n",
    "    ax_labels.set_xlabel(\"Label\")\n",
    "    ax_labels.set_ylabel(\"Probability\")\n",
    "    ax_labels.set_ylim([0, 1])\n",
    "    ax_labels.set_title(f\"True Label: {true_label}\")\n",
    "\n",
    "def train_interactive(learning_rate, network, dropout):\n",
    "    iteration = 0 \n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    momentum = 0.001\n",
    "    num_epochs = 5\n",
    "\n",
    "    train_losses, test_losses = [], []\n",
    "    train_accuracies, test_accuracies = [], []\n",
    "    if network == \"FeedForward\":\n",
    "        network = FeedForwardNetwork(dropout)\n",
    "    else:\n",
    "        network = ConvolutionalNetwork(dropout)\n",
    "    optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            with torch.no_grad():\n",
    "                loss, accuracy = evaluate_epoch(network, test_loader, criterion)\n",
    "                test_losses.append(loss)\n",
    "                test_accuracies.append(accuracy)\n",
    "                x_test.append(iteration)\n",
    "\n",
    "            for data, target in train_loader:\n",
    "                network.train()\n",
    "                loss, accuracy = train_step(network, criterion, optimizer, data, target)\n",
    "                train_losses.append(loss)\n",
    "                train_accuracies.append(accuracy)\n",
    "                x_train.append(iteration)\n",
    "\n",
    "                if ((iteration + 1) % 50) == 0:\n",
    "                    IPython.display.clear_output(wait=True)\n",
    "                    plt.close()\n",
    "                    epoch_str = f\"epoch [{epoch + 1}/{num_epochs}], iter {iteration + 1}\"\n",
    "                    train_str = f\"train loss:{loss:.4f}, train accuracy:{accuracy:.4f}\"\n",
    "                    test_str = f\"test loss:{test_losses[-1]:.4f}, test accuracy:{test_accuracies[-1]:.4f}\"\n",
    "                    print(f\"{epoch_str}, {train_str}, {test_str}\")\n",
    "                    fig, ax = plt.subplots(2,2)\n",
    "                    ax_losses = ax[1, 0]\n",
    "                    ax_accuracies = ax[1, 1]\n",
    "                    ax_image = ax[0, 0]\n",
    "                    ax_labels = ax[0, 1]\n",
    "\n",
    "                    plot_losses(x_train, train_losses, x_test, test_losses, ax_losses)\n",
    "                    plot_accuracies(x_train, train_accuracies, x_test, test_accuracies, ax_accuracies)\n",
    "                    resample(network, test_loader, ax_image, ax_labels)\n",
    "\n",
    "                    plt.show()\n",
    "\n",
    "                iteration += 1\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        loss, accuracy = evaluate_epoch(network, test_loader, criterion)\n",
    "        test_losses.append(loss)\n",
    "        test_accuracies.append(accuracy)\n",
    "        x_test.append(iteration)\n",
    "\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    plt.close()\n",
    "    epoch_str = f\"epoch [{epoch + 1}/{num_epochs}], iter {iteration + 1}\"\n",
    "    train_str = f\"train loss:{loss:.4f}, train accuracy:{accuracy:.4f}\"\n",
    "    test_str = f\"test loss:{test_losses[-1]:.4f}, test accuracy:{test_accuracies[-1]:.4f}\"\n",
    "    print(f\"{epoch_str}, {train_str}, {test_str}\")\n",
    "    fig, ax = plt.subplots(2,2)\n",
    "    ax_losses = ax[1, 0]\n",
    "    ax_accuracies = ax[1, 1]\n",
    "    ax_image = ax[0, 0]\n",
    "    ax_labels = ax[0, 1]\n",
    "\n",
    "    plot_losses(x_train, train_losses, x_test, test_losses, ax_losses)\n",
    "    plot_accuracies(x_train, train_accuracies, x_test, test_accuracies, ax_accuracies)\n",
    "    resample(network, test_loader, ax_image, ax_labels)\n",
    "\n",
    "    plt.show()\n",
    "            \n",
    "interact_manual(\n",
    "    train_interactive, \n",
    "    learning_rate=ipywidgets.FloatLogSlider(value=0.01, min=-5, max=0), \n",
    "    network=[\"FeedForward\", \"Convolutional\"],\n",
    "    dropout=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Universal function Aproximator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:30:34.958744Z",
     "start_time": "2022-04-04T07:30:34.402908Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 5)\n",
    "from sklearn import svm\n",
    "import IPython \n",
    "def laplacian_kernel(X, Y, bw):\n",
    "    rows = X.shape[0]\n",
    "    cols = Y.shape[0]\n",
    "    K = np.zeros((rows, cols))\n",
    "    for col in range(cols):\n",
    "        dist = bw * np.linalg.norm(X - Y[col, :], ord=1, axis=1)\n",
    "        K[:, col] = np.exp(-dist)\n",
    "    return K\n",
    "\n",
    "def process_regressor(regressor, xtrain, ytrain, xplot, yplot):\n",
    "    regressor.fit(np.reshape(xtrain, (xtrain.size, 1)), ytrain)\n",
    "\n",
    "    yhat = regressor.predict(np.reshape(xplot, (xplot.size, 1)))\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    \n",
    "    plt.scatter(xtrain, ytrain, label=\"Training data\", alpha=0.2)\n",
    "    plt.plot(xplot, yplot, 'r-', label=\"True Function\")\n",
    "    plt.plot(xplot, yhat, 'g-', label=\"Prediction\")\n",
    "\n",
    "    plt.legend(loc='lower center');\n",
    "    plt.ylim([np.min(yplot)*1.1, np.max(yplot)*1.1])\n",
    "\n",
    "def NNregressor(activation, solver, hidden_layer_size, reg, xtrain, ytrain, xplot, yplot):\n",
    "    regressor = MLPRegressor(activation=activation,\n",
    "                                 solver=solver,\n",
    "                                 alpha=reg,\n",
    "                                 random_state=0,\n",
    "                                 hidden_layer_sizes=hidden_layer_size,\n",
    "                                 tol=1e-6,\n",
    "                                 max_iter=1000\n",
    "                                )\n",
    "    process_regressor(regressor, xtrain, ytrain, xplot, yplot)\n",
    "\n",
    "def SVMregressor(kernel, bw, reg, xtrain, ytrain, xplot, yplot):\n",
    "    if kernel == 'rbf':\n",
    "        gamma = np.power(10., -bw)\n",
    "        coef0 = 0\n",
    "    elif kernel == 'laplacian':\n",
    "        gamma = np.power(10., -bw)\n",
    "        coef0 = 0\n",
    "        kernel = lambda X, Y: laplacian_kernel(X, Y, gamma)\n",
    "        \n",
    "    regressor = svm.SVR(kernel=kernel, C=1./reg, gamma=gamma,coef0=coef0)\n",
    "    process_regressor(regressor, xtrain, ytrain, xplot, yplot)\n",
    "\n",
    "    \n",
    "def uat_demo(function, n_samples, noise, family):\n",
    "    if function == 1:\n",
    "        f = lambda x: np.sin(x) \n",
    "    elif function == 2:\n",
    "        f = lambda x: np.sin(x) * np.exp(np.abs(x))\n",
    "    elif function == 3:\n",
    "        f = lambda x: np.sin(x) * np.floor(np.abs(x))\n",
    "    elif function == 4:\n",
    "        f = lambda x: np.sin(x * np.floor(np.abs(x)))\n",
    "\n",
    "    xmin = -6\n",
    "    xmax = +6\n",
    "    xplot = np.arange(xmin, xmax, 0.01)\n",
    "    yplot = f(xplot)\n",
    "\n",
    "    xtrain = xmin + (xmax -xmin) * np.random.rand(n_samples)\n",
    "    ytrain = f(xtrain) + noise * np.random.randn(xtrain.size)\n",
    "    \n",
    "    plt.scatter(xtrain, ytrain, label=\"Training data\", alpha=0.2)\n",
    "    plt.plot(xplot, yplot, 'r-', label=\"True Function\")\n",
    "\n",
    "    plt.legend(loc='lower center');\n",
    "    plt.ylim([np.min(yplot)*1.1, np.max(yplot)*1.1])\n",
    "    plt.show()\n",
    "    if family == 'NN':\n",
    "        regressor = interact_manual(\n",
    "            NNregressor,\n",
    "            solver=['lbfgs', 'sgd', 'adam'],\n",
    "            activation=['relu', 'identity', 'logistic'],\n",
    "            hidden_layer_size=[(1,), (5, ), (50, ), (100, ), (1000, ),\n",
    "                                   (5, 5, ), (50, 50, ), (100, 100), \n",
    "                                   (50, 50, 50), (100, 100, 100)],\n",
    "            reg=[0, 10**-3, 10**-2, 10**-1, 1], \n",
    "            xtrain=fixed(xtrain), \n",
    "            ytrain=fixed(ytrain), \n",
    "            xplot=fixed(xplot), \n",
    "            yplot=fixed(yplot))\n",
    "        \n",
    "    elif family == 'SVM':\n",
    "        regressor = interact_manual(\n",
    "            SVMregressor,\n",
    "            kernel=['rbf', 'laplacian'],\n",
    "            bw=ipywidgets.FloatSlider(value=-1,\n",
    "                                    min=-3,\n",
    "                                    max=3,\n",
    "                                    step=0.1,\n",
    "                                    readout_format='.1f',\n",
    "                                    description='Bandwidth 10^:',\n",
    "                                    style={'description_width': 'initial'},\n",
    "                                    continuous_update=False),\n",
    "            reg=[10**-3, 10**-2, 10**-1, 1], \n",
    "            xtrain=fixed(xtrain), \n",
    "            ytrain=fixed(ytrain), \n",
    "            xplot=fixed(xplot), \n",
    "            yplot=fixed(yplot))\n",
    "\n",
    "interact(uat_demo, \n",
    "                n_samples=[100, 200, 500, 1000, 10000],\n",
    "                noise=[0, 0.01, 0.05, 0.1, 0.5,],\n",
    "                function=ipywidgets.ToggleButtons(value=1, \n",
    "                                                  options=[1, 2, 3, 4], \n",
    "                                                  description='Function:',\n",
    "                                                  style={'description_width': 'initial'}),\n",
    "                family=['NN', 'SVM']\n",
    "               );\n",
    "\n",
    "# add plot of function as soon as the cell is run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Learning strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T07:29:52.111341Z",
     "start_time": "2022-04-04T07:29:50.445579Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# different learning rate schedules and momentum parameters\n",
    "params = [{'solver': 'sgd', 'learning_rate': 'constant', 'momentum': 0,\n",
    "           'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'constant', 'momentum': .9,\n",
    "           'nesterovs_momentum': False, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'constant', 'momentum': .9,\n",
    "           'nesterovs_momentum': True, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': 0,\n",
    "           'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': .9,\n",
    "           'nesterovs_momentum': True, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': .9,\n",
    "           'nesterovs_momentum': False, 'learning_rate_init': 0.2},\n",
    "          {'solver': 'adam', 'learning_rate_init': 0.01}]\n",
    "\n",
    "labels = [\"constant learning-rate\", \"constant with momentum\",\n",
    "          \"constant with Nesterov's momentum\",\n",
    "          \"inv-scaling learning-rate\", \"inv-scaling with momentum\",\n",
    "          \"inv-scaling with Nesterov's momentum\", \"adam\"]\n",
    "\n",
    "plot_args = [{'c': 'red', 'linestyle': '-'},\n",
    "             {'c': 'green', 'linestyle': '-'},\n",
    "             {'c': 'blue', 'linestyle': '-'},\n",
    "             {'c': 'red', 'linestyle': '--'},\n",
    "             {'c': 'green', 'linestyle': '--'},\n",
    "             {'c': 'blue', 'linestyle': '--'},\n",
    "             {'c': 'black', 'linestyle': '-'}]\n",
    "\n",
    "def plot_on_dataset(dataset):\n",
    "    # Load datasets. \n",
    "    plt.figure()\n",
    "    max_iter = 400\n",
    "    if dataset == \"iris\":\n",
    "        data = datasets.load_iris()\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "    elif dataset == \"digits\":\n",
    "        data = datasets.load_digits()\n",
    "        X = data.data\n",
    "        y = data.target\n",
    "        max_iter = 15\n",
    "    elif dataset == \"circles\":\n",
    "        X, y = datasets.make_circles(noise=0.2, factor=0.5, random_state=1)\n",
    "    elif dataset == 'moons':\n",
    "        X, y =  datasets.make_moons(noise=0.3, random_state=0)\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "    \n",
    "    # Train Classifiers.\n",
    "    classifiers = []\n",
    "    for label, param in zip(labels, params):\n",
    "        classifier = MLPClassifier(verbose=0, \n",
    "                                    random_state=0,\n",
    "                                    max_iter=max_iter, **param)\n",
    "        classifier.fit(X, y)\n",
    "        classifiers.append(classifier)\n",
    "    for classifier, label, args in zip(classifiers, labels, plot_args):\n",
    "            plt.plot(classifier.loss_curve_, label=label, **args)\n",
    "            \n",
    "    plt.legend(ncol=2, loc=\"best\")\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('Error')\n",
    "\n",
    "interact(plot_on_dataset, dataset=['iris', 'digits', 'circles', 'moons']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
